{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "academic-pressure",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import krakenex\n",
    "from pandas import json_normalize\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "import pygsheets\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-basketball",
   "metadata": {},
   "source": [
    "## Authentitication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = krakenex.API()\n",
    "k.load_key('kraken.key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-burton",
   "metadata": {},
   "source": [
    "## Call the positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pf_status = k.query_private('Balance')\n",
    "current_pf_status = current_pf_status['result']\n",
    "current_pf_status = pd.DataFrame.from_dict(current_pf_status, orient='index').reset_index()\n",
    "current_pf_status = current_pf_status.rename(columns={\"index\": \"crypto\", 0: \"value\"})\n",
    "current_pf_status['time'] = dt.date.today()\n",
    "current_pf_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-farming",
   "metadata": {},
   "source": [
    "## Get the list of transactions all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-relation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_one_month(t):\n",
    "    one_day = dt.timedelta(days=1)\n",
    "    one_month_later = t + one_day\n",
    "    while one_month_later.month == t.month:  # advance to start of next month\n",
    "        one_month_later += one_day\n",
    "    target_month = one_month_later.month\n",
    "    while one_month_later.day < t.day:  # advance to appropriate day\n",
    "        one_month_later += one_day\n",
    "        if one_month_later.month != target_month:  # gone too far\n",
    "            one_month_later -= one_day\n",
    "            break\n",
    "    return one_month_later\n",
    "\n",
    "start = dt.date(2021, 1, 1)\n",
    "\n",
    "#let's create the master dataset that will list all transactions\n",
    "transactions_column_names = ['refid', 'time', 'type', 'subtype', 'aclass', 'asset', 'amount', 'fee', 'balance']\n",
    "transactions_df = pd.DataFrame(columns = transactions_column_names)\n",
    "\n",
    "while start < dt.date.today():\n",
    "    \n",
    "    #create the end date one month later\n",
    "    end = add_one_month(start)\n",
    "    #format the dates into unix for the api parameters\n",
    "    formatted_start = time.mktime(start.timetuple())\n",
    "    formatted_end = time.mktime(end.timetuple())\n",
    "    #change the start date for the next loop\n",
    "    start = end\n",
    "    \n",
    "    #let's call the endpoint to have all transaction details in EUR\n",
    "    req_data = {'aclass': 'ZEUR',\n",
    "                'start': formatted_start,\n",
    "                'end': formatted_end\n",
    "                }\n",
    "    transactions = k.query_private('Ledgers', req_data)\n",
    "    \n",
    "    if transactions.get('error'):\n",
    "        pass\n",
    "    \n",
    "    elif transactions['result']['ledger'] is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        transactions = transactions['result']['ledger']\n",
    "        transactions = json_normalize(transactions)\n",
    "        \n",
    "        #let's pull out the list of all ledger IDs\n",
    "        ledger_list = list(transactions.columns)\n",
    "        sep = '.'\n",
    "        ledger_list = [i.split(sep, 1)[0] for i in ledger_list]\n",
    "        clean_ledger_list=[]\n",
    "        for i in ledger_list:\n",
    "          if i not in clean_ledger_list:\n",
    "            clean_ledger_list.append(i)\n",
    "        \n",
    "        #let's create the temporary dataset that will list all transactions\n",
    "        temp_df = pd.DataFrame(columns = transactions_column_names)\n",
    "        \n",
    "        #let's loop over the list of ledgers to get all the transactions and add them to the master dataframe\n",
    "        all_transactions = k.query_private('Ledgers', req_data)\n",
    "        for i in clean_ledger_list:\n",
    "            transaction_row = all_transactions['result']['ledger'][i]\n",
    "            transaction_row = json_normalize(transaction_row)\n",
    "            temp_df = temp_df.append(transaction_row)\n",
    "    transactions_df = transactions_df.append(temp_df)\n",
    "transactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-translator",
   "metadata": {},
   "source": [
    "## Transform the dataframe to crypto Vs. euro rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-terrain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deposit = transactions_df\n",
    "deposit['fee'] =  deposit['fee'].apply(lambda x: float(x))\n",
    "deposit = deposit[deposit['type'] == 'deposit']\n",
    "deposit = deposit.filter(items=['time', 'refid', 'fee', 'amount'])\n",
    "deposit['time'] = pd.to_datetime(deposit['time'],unit='s')\n",
    "deposit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-renewal",
   "metadata": {},
   "source": [
    "## Calculate the internal flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_flows = transactions_df\n",
    "internal_flows = internal_flows[internal_flows['type'] == 'spend']\n",
    "internal_flows = internal_flows.filter(items=['time', 'refid', 'asset', 'amount'])\n",
    "internal_flows['time'] = pd.to_datetime(internal_flows['time'],unit='s')\n",
    "internal_flows = internal_flows[internal_flows['asset'] != 'EUR.HOLD']\n",
    "internal_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-consultation",
   "metadata": {},
   "source": [
    "## Calculate the incoming crypto flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-future",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crypto_positive = transactions_df\n",
    "crypto_positive = crypto_positive[crypto_positive['type'] == 'receive']\n",
    "crypto_positive = crypto_positive.filter(items=['time', 'refid', 'asset', 'amount'])\n",
    "crypto_positive['time'] = pd.to_datetime(crypto_positive['time'],unit='s')\n",
    "crypto_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-sucking",
   "metadata": {},
   "source": [
    "## Create a daily dataframe containing all portfolio transactions regardless of the crypto or currency flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-sussex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ongoing_portfolio = crypto_positive.append(internal_flows)\n",
    "ongoing_portfolio['time'] = ongoing_portfolio['time'].dt.strftime('%Y-%m-%d')\n",
    "ongoing_portfolio['time'] = pd.to_datetime(ongoing_portfolio['time'], format='%Y-%m-%d')\n",
    "ongoing_portfolio = ongoing_portfolio.filter(items=['time', 'asset', 'amount'])\n",
    "\n",
    "# create a range of dates for the merged dataframe\n",
    "index_of_dates = pd.date_range('2020-01-01', date.today()).to_frame().reset_index(drop=True).rename(columns={0: 'time'})\n",
    "\n",
    "# create a merged dataframe with date / asset / transactions \n",
    "ongoing_portfolio = pd.merge(index_of_dates,ongoing_portfolio,how='left', on='time')\n",
    "ongoing_portfolio = ongoing_portfolio.rename(columns={'asset': 'crypto'})\n",
    "ongoing_portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-layer",
   "metadata": {},
   "source": [
    "## Add the value of the crypto to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of all crypto that are available in the portfolio\n",
    "crypto_list = ongoing_portfolio['crypto'].replace({'XMLN':'XMLNZ', 'XXDG':'XDG'}).dropna().unique()\n",
    "crypto_list = crypto_list + 'EUR'\n",
    "crypto_list\n",
    "\n",
    "#set up an empty crypto df\n",
    "crypto_value_columns = ['time','crypto', 'crypto_value']\n",
    "crypto_value_df = pd.DataFrame(columns = crypto_value_columns)\n",
    "\n",
    "for i in crypto_list:\n",
    "    \n",
    "    #set up the start date of the loop\n",
    "    start = dt.date(2021, 1, 1)\n",
    "    formatted_start = time.mktime(start.timetuple())\n",
    "    \n",
    "    #let's call the endpoint to have all transaction details in EUR\n",
    "    req_data = {'pair': i,\n",
    "                'interval': '1440',\n",
    "                'since': formatted_start\n",
    "                }\n",
    "    crypto_value = k.query_public('OHLC', req_data)\n",
    "    \n",
    "    if crypto_value.get('error'):\n",
    "        pass\n",
    "    \n",
    "    elif crypto_value['result'][i] is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        crypto_value = crypto_value['result'][i]\n",
    "        crypto_value = pd.DataFrame.from_records(crypto_value)\n",
    "        crypto_value[0] = pd.to_datetime(crypto_value[0],unit='s')\n",
    "        crypto_value['crypto'] = i\n",
    "        crypto_value = crypto_value.rename(columns={0: \"time\", 1: \"crypto_value\"})\n",
    "        crypto_value = crypto_value.filter(items=['time', 'crypto', 'crypto_value'])\n",
    "    \n",
    "    crypto_value_df = crypto_value_df.append(crypto_value, ignore_index=True)\n",
    "\n",
    "crypto_value_df['time'] = pd.to_datetime(crypto_value_df['time'])\n",
    "crypto_value_df['crypto'] = crypto_value_df['crypto'].apply(lambda x: str(x)[:-3])\n",
    "crypto_value_df['crypto'] = crypto_value_df['crypto'].replace('XMLNZ', 'XMLN')\n",
    "crypto_value_df['crypto'] = crypto_value_df['crypto'].replace('XDG', 'XXDG')\n",
    "crypto_value_df = crypto_value_df.drop(columns=['error'])\n",
    "crypto_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-trinidad",
   "metadata": {},
   "source": [
    "## Join to the current pf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_crypto_value =  current_pf_status.set_index(['time', 'crypto']).join(crypto_value_df.set_index(['time', 'crypto'])).reset_index()\n",
    "last_crypto_value['value'] = last_crypto_value['value'].apply(lambda x: float(x))\n",
    "last_crypto_value['crypto_value'] = last_crypto_value['crypto_value'].apply(lambda x: float(x))\n",
    "last_crypto_value['total_crypto_value'] = last_crypto_value['value']*last_crypto_value['crypto_value']\n",
    "last_crypto_value = last_crypto_value.replace(np.nan, '')\n",
    "last_crypto_value = last_crypto_value[last_crypto_value['total_crypto_value'] != '']\n",
    "last_crypto_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorization\n",
    "gc = pygsheets.authorize(service_file='kraken-reporting-key-sheets.json')\n",
    "\n",
    "#open the google spreadsheetkraken-credentials\n",
    "sh = gc.open(\"Kraken reporting\")\n",
    "\n",
    "#select the first sheet\n",
    "wks = sh[2]\n",
    "\n",
    "#update the required sheet\n",
    "wks.set_dataframe(last_crypto_value,(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-aggregate",
   "metadata": {},
   "source": [
    "## Join to the ongoing portfolio with the crypto values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = crypto_value_df.set_index(['time', 'crypto']).join(ongoing_portfolio.set_index(['time', 'crypto'])).reset_index()\n",
    "final_df = final_df.drop(columns=['crypto_value'])\n",
    "final_df['amount'] = final_df['amount'].apply(lambda x: float(x))\n",
    "final_df = final_df.replace(np.nan, 0)\n",
    "final_df['cum_amount'] = final_df.groupby(['crypto']).amount.cumsum()\n",
    "\n",
    "final_df = final_df[final_df['cum_amount'] != 0]\n",
    "final_df['time'] = pd.to_datetime(final_df['time'])\n",
    "final_df = final_df.set_index(['time', 'crypto']).join(crypto_value_df.set_index(['time', 'crypto'])).reset_index()\n",
    "final_df['cum_amount'] = final_df['cum_amount'].apply(lambda x: float(x))\n",
    "final_df['crypto_value'] = final_df['crypto_value'].apply(lambda x: float(x))\n",
    "final_df['cum_amount_eur_value'] = final_df['cum_amount']*final_df['crypto_value']\n",
    "final_df = final_df.filter(items=['time', 'crypto', 'crypto_value', 'amount', 'cum_amount', 'cum_amount_eur_value'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorization\n",
    "gc = pygsheets.authorize(service_file='kraken-reporting-key-sheets.json')\n",
    "\n",
    "#open the google spreadsheetkraken-credentials\n",
    "sh = gc.open(\"Kraken reporting\")\n",
    "\n",
    "#select the first sheet\n",
    "wks = sh[3]\n",
    "\n",
    "#update the required sheet\n",
    "wks.set_dataframe(final_df,(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-overall",
   "metadata": {},
   "source": [
    "## Send the raw transaction df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = transactions_df\n",
    "raw_dataframe['time'] = pd.to_datetime(raw_dataframe['time'],unit='s')\n",
    "raw_dataframe['time'] = raw_dataframe['time'].dt.strftime('%Y-%m-%d')\n",
    "raw_dataframe = raw_dataframe.filter(items=['refid', 'time', 'asset', 'amount', 'fee', 'balance'])\n",
    "\n",
    "#authorization\n",
    "gc = pygsheets.authorize(service_file='kraken-reporting-key-sheets.json')\n",
    "\n",
    "#open the google spreadsheetkraken-credentials\n",
    "sh = gc.open(\"Kraken reporting\")\n",
    "\n",
    "#select the first sheet\n",
    "wks = sh[0]\n",
    "\n",
    "#update the required sheet\n",
    "wks.set_dataframe(raw_dataframe,(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-nation",
   "metadata": {},
   "source": [
    "## Add aggregated portfolio value to the deposit df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-score",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a dataframe with euro spending\n",
    "eur_spending = deposit\n",
    "eur_spending = eur_spending.filter(items=['time', 'amount']).rename(columns={\"amount\": \"eur_spent\"})\n",
    "eur_spending['eur_spent'] = eur_spending['eur_spent'].apply(lambda x: float(x))\n",
    "eur_spending = eur_spending.groupby(['time']).sum().reset_index()\n",
    "eur_spending['time'] = pd.to_datetime(eur_spending['time']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#create amn aggregated dataframe of crypto values\n",
    "aggregated_df = final_df\n",
    "aggregated_df = aggregated_df.groupby(['time']).sum().reset_index()\n",
    "aggregated_df['time'] = pd.to_datetime(aggregated_df['time']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#combine both dataframes to have both spending and porftolio value\n",
    "aggregated_df = aggregated_df.set_index('time').join(eur_spending.set_index('time')).reset_index()\n",
    "aggregated_df['eur_spent'] = aggregated_df['eur_spent'].replace(np.nan, 0)\n",
    "aggregated_df['eur_spent'] = aggregated_df['eur_spent'].apply(lambda x: float(x))\n",
    "aggregated_df['cum_eur_spent'] = aggregated_df.eur_spent.cumsum()\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorization\n",
    "gc = pygsheets.authorize(service_file='kraken-reporting-key-sheets.json')\n",
    "\n",
    "#open the google spreadsheetkraken-credentials\n",
    "sh = gc.open(\"Kraken reporting\")\n",
    "\n",
    "#select the first sheet\n",
    "wks = sh[1]\n",
    "\n",
    "#update the required sheet\n",
    "wks.set_dataframe(aggregated_df,(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
